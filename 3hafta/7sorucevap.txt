# Hafta 3 - Ä°leri Algoritmalar Soru & Cevap

## ğŸ§  Dynamic Programming

**S1: Dynamic Programming'in temel prensipi nedir?**
**C:** **"Overlapping subproblems'larÄ± bir kez Ã§Ã¶z, sonuÃ§larÄ± sakla, tekrar kullan"**. Optimal substructure + overlapping subproblems = DP. Recursive Ã§Ã¶zÃ¼mÃ¼n exponential time'Ä±nÄ± polynomial time'a dÃ¼ÅŸÃ¼rÃ¼r.

**S2: Memoization ile Tabulation arasÄ±ndaki fark nedir?**
**C:** 
- **Memoization:** Top-down, recursive + cache. Natural ama function call overhead var
- **Tabulation:** Bottom-up, iterative + table. Efficient ama less intuitive

**S3: Fibonacci iÃ§in naive recursive O(2â¿) neden bu kadar yavaÅŸ?**
**C:** **AynÄ± deÄŸerleri tekrar tekrar hesaplÄ±yor**. Fib(5) hesaplarken Fib(3)'Ã¼ 2 kez, Fib(2)'yi 3 kez hesaplar. DP ile O(n)'e dÃ¼ÅŸer.

**S4: House Robber probleminin DP formÃ¼lÃ¼ nedir?**
**C:** `dp[i] = Math.Max(nums[i] + dp[i-2], dp[i-1])` - Bu evi soy + 2 Ã¶nceki max vs bu evi soyma + Ã¶nceki max.

**S5: Coin Change'de neden bottom-up yaklaÅŸÄ±m kullanÄ±rÄ±z?**
**C:** **KÃ¼Ã§Ã¼k amount'lar iÃ§in optimal solution bulduktan sonra, bÃ¼yÃ¼k amount'larÄ± bunlarÄ± kullanarak Ã§Ã¶zeriz**. Her amount iÃ§in tÃ¼m coin'leri deneyip minimum buluruz.

**S6: 2D DP problemlerinde state tanÄ±mÄ± nasÄ±l yapÄ±lÄ±r?**
**C:** **dp[i][j]** genelde **"i pozisyonuna kadar j constraint ile optimal solution"** anlamÄ±na gelir. Unique Paths'te dp[i][j] = (i,j)'ye kaÃ§ yoldan ulaÅŸÄ±lÄ±r.

**S7: LCS (Longest Common Subsequence) algoritmasÄ±nÄ±n recurrence relation'Ä± nedir?**
**C:** 
```
if (s1[i] == s2[j]): dp[i][j] = 1 + dp[i-1][j-1]
else: dp[i][j] = max(dp[i-1][j], dp[i][j-1])
```

**S8: 0/1 Knapsack ile Fractional Knapsack arasÄ±ndaki fark nedir?**
**C:** 
- **0/1 Knapsack:** Item'i bÃ¶lemezsin â†’ DP gerekir â†’ O(nW)
- **Fractional:** Item'i bÃ¶lebilirsin â†’ Greedy yeter â†’ O(n log n)

**S9: DP problem'i nasÄ±l identify edersin?**
**C:** 
1. **Optimization** (min/max) veya **counting** problem
2. **Optimal substructure** var mÄ±?
3. **Overlapping subproblems** var mÄ±?
4. **Future decisions** previous decisions'a baÄŸlÄ± mÄ±?

**S10: Space optimization nasÄ±l yapÄ±lÄ±r?**
**C:** **Sadece previous state'leri tutarak** table size'Ä±nÄ± kÃ¼Ã§Ã¼ltÃ¼rÃ¼z. Fibonacci'de n boyutlu array yerine 2 variable yeter. 2D DP'de genelde 1D array'e optimize edilebilir.

---

## ğŸ’š Greedy Algorithms

**S11: Greedy algorithm'Ä±n temel felsefesi nedir?**
**C:** **"Her adÄ±mda local optimal choice yap, gerisini dÃ¼ÅŸÃ¼nme"**. Global optimal'a ulaÅŸmayÄ± garanti etmez ama Ã§oÄŸu zaman yeterince iyi + Ã§ok hÄ±zlÄ±.

**S12: Activity Selection'da neden "earliest end time" greedy choice'Ä± optimal?**
**C:** **En erken biten activity, gelecekteki en fazla activity iÃ§in yer bÄ±rakÄ±r**. Matematiksel olarak kanÄ±tlanabilir ki bu choice global optimal'a gÃ¶tÃ¼rÃ¼r.

**S13: Fractional Knapsack'te greedy strategy nedir?**
**C:** **Value/weight ratio'su en yÃ¼ksek item'larÄ± Ã¶nce al**. Birim aÄŸÄ±rlÄ±k baÅŸÄ±na en deÄŸerli item'lar optimal Ã§Ã¶zÃ¼mde yer alÄ±r.

**S14: Standard coin systems iÃ§in Greedy Coin Change neden Ã§alÄ±ÅŸÄ±r?**
**C:** **[1,5,10,25] gibi sistemlerde bÃ¼yÃ¼k coin'i kullanmak her zaman optimal**. Ama [1,3,4] amount=6 iÃ§in Greedy [4,1,1] (3 coin), Optimal [3,3] (2 coin) verir.

**S15: Jump Game'de greedy approach nasÄ±l Ã§alÄ±ÅŸÄ±r?**
**C:** **Åimdiye kadar ulaÅŸabileceÄŸimiz en uzak noktayÄ± track ederiz**. Her position'da `maxReach = max(maxReach, i + nums[i])` gÃ¼ncellenir.

**S16: Meeting Rooms probleminde neden start/end time'larÄ± ayrÄ± sÄ±ralÄ±yoruz?**
**C:** **Event-based simulation** - Her time point'te kaÃ§ meeting aktif kontrol ederiz. Start event +1 room, end event -1 room demek.

**S17: Gas Station probleminde start point'i nasÄ±l belirliyoruz?**
**C:** **Current gas negative olursa o start point Ã§alÄ±ÅŸmaz demektir**. Bir sonraki position'dan yeni start deneriz. Total gas yetiyorsa bir solution mutlaka vardÄ±r.

**S18: Greedy algorithm'Ä±n correctness'ini nasÄ±l kanÄ±tlarsÄ±n?**
**C:** **Exchange argument**: Optimal solution'da greedy choice olmasaydÄ±, onu greedy choice ile deÄŸiÅŸtirip daha iyi/eÅŸit solution elde edebileceÄŸimizi gÃ¶steririz.

**S19: Greedy vs DP - hangi durumda hangisini kullanÄ±rsÄ±n?**
**C:** 
- **Greedy:** Local optimal â†’ global optimal + hÄ±z Ã¶nemli
- **DP:** Overlapping subproblems + optimal solution garanti

**S20: Hangi problemlerde Greedy kesinlikle Ã§alÄ±ÅŸmaz?**
**C:** **0/1 Knapsack, LCS, shortest path (negative weights), coin change (non-standard)** - Bu problemlerde future consequences local choice'larÄ± etkiler.

---

## ğŸ”ï¸ Heap & Priority Queue

**S21: Heap'in temel property'si nedir?**
**C:** 
- **Shape property:** Complete binary tree
- **Heap property:** Parent â‰¥ children (max heap) veya parent â‰¤ children (min heap)

**S22: Heap'i array'de nasÄ±l represent ederiz?**
**C:** **Index 0'dan baÅŸlayarak**: Parent(i) = (i-1)/2, LeftChild(i) = 2i+1, RightChild(i) = 2i+2. Bu sayede pointer gerektirmez.

**S23: Heap'te insert operation'Ä± nasÄ±l Ã§alÄ±ÅŸÄ±r?**
**C:** 
1. **Array'in sonuna ekle** (complete tree property iÃ§in)
2. **Heapify up** - parent'tan kÃ¼Ã§Ã¼kse (min heap) swap et, root'a kadar devam et
3. **Time: O(log n)**

**S24: Extract min/max neden O(log n) sÃ¼rer?**
**C:** 
1. **Root'taki min/max'Ä± al**
2. **Son elemanÄ± root'a taÅŸÄ±, son elemanÄ± sil**
3. **Heapify down** - child'lardan kÃ¼Ã§Ã¼k olanla swap et, leaf'e kadar
4. **Tree height = log n, worst case tÃ¼m tree'yi traverse**

**S25: Build heap iÅŸlemi neden O(n) time alÄ±r?**
**C:** **Bottom-up heapify**: Son non-leaf'ten baÅŸlayÄ±p root'a kadar heapify. Mathematical analysis gÃ¶sterir ki total work O(n).

**S26: Top K elements bulma iÃ§in hangi heap kullanÄ±lÄ±r?**
**C:** 
- **K largest:** Min heap (size k) - kÃ¼Ã§Ã¼ÄŸÃ¼ Ã§Ä±kar, bÃ¼yÃ¼kleri sakla
- **K smallest:** Max heap (size k) - bÃ¼yÃ¼ÄŸÃ¼ Ã§Ä±kar, kÃ¼Ã§Ã¼kleri sakla

**S27: Merge K sorted lists'te heap nasÄ±l kullanÄ±lÄ±r?**
**C:** **Her list'in head'ini heap'e at, en kÃ¼Ã§Ã¼ÄŸÃ¼ al, o list'in next'ini heap'e at**. Her adÄ±mda K elemanlÄ± heap maintain ederiz.

**S28: Median from data stream problemi nasÄ±l Ã§Ã¶zÃ¼lÃ¼r?**
**C:** **Ä°ki heap kullan**: MaxHeap (lower half), MinHeap (upper half). Balance maintain et, median heap'lerin peek'lerinden bulunur.

**S29: Dijkstra algorithm'da heap'in rolÃ¼ nedir?**
**C:** **Distance'a gÃ¶re node'larÄ± prioritize eder**. En yakÄ±n unvisited node'u her zaman Ã¶nce process eder. Min heap kullanÄ±lÄ±r.

**S30: Heap vs BST - ne zaman hangisini kullanÄ±rsÄ±n?**
**C:** 
- **Heap:** Priority operations (min/max), no search needed
- **BST:** Search operations, sorted traversal, range queries

---

## ğŸ”— Union-Find (Disjoint Set)

**S31: Union-Find'Ä±n temel amacÄ± nedir?**
**C:** **Dynamic connectivity queries'i efficiently handle etmek**. "Ä°ki eleman aynÄ± component'te mi?" sorusunu neredeyse O(1)'de cevaplar.

**S32: Path compression nasÄ±l Ã§alÄ±ÅŸÄ±r?**
**C:** **Find operation sÄ±rasÄ±nda tÃ¼m node'larÄ± direkt root'a baÄŸlarÄ±z**. Recursive: `parent[x] = Find(parent[x])`. Tree'yi dÃ¼zleÅŸtirerek future queries'i hÄ±zlandÄ±rÄ±r.

**S33: Union by rank/size'Ä±n mantÄ±ÄŸÄ± nedir?**
**C:** **KÃ¼Ã§Ã¼k tree'yi bÃ¼yÃ¼k tree'nin altÄ±na baÄŸlarÄ±z**. Bu tree'nin depth'ini minimize eder, Find operation'Ä±nÄ± hÄ±zlandÄ±rÄ±r.

**S34: Union-Find'Ä±n amortized complexity'si nedir?**
**C:** **O(Î±(n))** - Î± inverse Ackermann function. Pratik n deÄŸerleri iÃ§in â‰¤ 5, yani virtually constant.

**S35: Number of Islands problemi nasÄ±l Union-Find ile Ã§Ã¶zÃ¼lÃ¼r?**
**C:** **Her land cell'i komÅŸu land cell'leri ile union et**. Son'da total components - water cells = island count.

**S36: Kruskal's MST'de Union-Find'Ä±n rolÃ¼ nedir?**
**C:** **Cycle detection**: Edge eklenmeden Ã¶nce endpoints aynÄ± component'te mi kontrol ederiz. AynÄ± component'teyse cycle yaratÄ±r, eklemeyiz.

**S37: Friend Circles probleminde Union-Find nasÄ±l uygulanÄ±r?**
**C:** **Her person bir node, direct friendship edge**. Friend matrix'te M[i][j]=1 ise Union(i,j). Son'da component count = friend circle count.

**S38: Redundant Connection problemi nasÄ±l Ã§Ã¶zÃ¼lÃ¼r?**
**C:** **Edge'leri sÄ±rayla process ederiz**. Edge eklemeden Ã¶nce endpoints connected mi kontrol ederiz. Connected ise o edge redundant.

**S39: Union-Find'da rollback mÃ¼mkÃ¼n mÃ¼?**
**C:** **Path compression kullanmazsak mÃ¼mkÃ¼n**. Union operation'larÄ±nÄ± stack'te tutarÄ±z, rollback iÃ§in reverse ederiz. Ama complexity artar.

**S40: Hangi durumlarda Union-Find kullanmamalÄ±sÄ±n?**
**C:** 
- **Path queries** gerekiyorsa (shortest path)
- **Disconnection** operations gerekiyorsa
- **Directed graph** problems
- **Weighted connectivity** (Union-Find unweighted)

---

## ğŸ¯ Algorithm Design & Problem Solving

**S41: Bir optimization problem gÃ¶rdÃ¼ÄŸÃ¼nde hangi technique'i dÃ¼ÅŸÃ¼nÃ¼rsÃ¼n?**
**C:** 
1. **Greedy work eder mi?** (local optimal â†’ global)
2. **DP patterns var mÄ±?** (overlapping subproblems)
3. **Graph problem mi?** (shortest path, MST)
4. **Search space'te binary search?** (monotonic property)

**S42: Recursive DP'den iterative DP'ye nasÄ±l geÃ§ersin?**
**C:** 
1. **Base cases'i identify et**
2. **Recurrence direction'Ä±nÄ± belirle** (bottom-up)
3. **Table'Ä± base cases ile initialize et**
4. **Recurrence relation'Ä± iterative olarak uygula**

**S43: Space optimization hangi DP problemlerinde mÃ¼mkÃ¼n?**
**C:** **Sadece previous row/column'a depend eden** problemlerde. 1D DP'de O(1), 2D DP'de O(min(m,n)) space'e optimize edilebilir.

**S44: Graph problem'ini gÃ¶rdÃ¼ÄŸÃ¼nde hangi algorithm'Ä± seÃ§ersin?**
**C:** 
- **Connectivity:** Union-Find
- **Shortest path:** Dijkstra (positive), Bellman-Ford (negative)
- **MST:** Kruskal (Union-Find), Prim (Heap)
- **Topological sort:** DFS/BFS

**S45: Algorithm complexity analyze ederken nelere dikkat edersin?**
**C:** 
1. **Dominant operations** (loops, recursive calls)
2. **Input size parameters** (n, m, k)
3. **Space usage** (extra arrays, recursion stack)
4. **Best/Average/Worst case** scenarios

**S46: Interview'da algorithm problem approach'Ä±n nasÄ±l olur?**
**C:** 
1. **Problem'i understand et** (examples, constraints)
2. **Brute force'dan baÅŸla** (correctness Ã¶nce)
3. **Optimize et** (bottleneck'leri identify et)
4. **Edge cases** (empty input, single element)
5. **Complexity analysis** (time + space)

**S47: Debugging algorithm'Ä±nda hangi teknik'leri kullanÄ±rsÄ±n?**
**C:** 
1. **Small examples** ile trace et
2. **Base cases** kontrol et
3. **Invariants** maintain ediliyor mu?
4. **State transitions** doÄŸru mu?
5. **Print statements** critical points'te

**S48: Advanced algorithm topics'e geÃ§mek iÃ§in hangi foundation gerekli?**
**C:** **DP + Greedy + Graph algorithms + data structures (heap, union-find) + complexity analysis**. Bu 4 teknik modern algorithm design'Ä±n %80'ini kapsar.

**S49: Real-world problem'i algorithm problem'ine nasÄ±l translate edersin?**
**C:** 
1. **Core problem'i extract et** (requirements'ten)
2. **Mathematical model'e Ã§evir** (graph, array, tree)
3. **Constraints'leri identify et** (time, space, accuracy)
4. **Known patterns'e map et** (DP, greedy, graph)

**S50: Performance critical system'de hangi algorithm choices yaparsin?**
**C:** 
1. **Time vs Space tradeoff** (caching vs computation)
2. **Average case'i optimize et** (worst case nadir)
3. **Parallelizable** algorithms tercih et
4. **Cache-friendly** memory access patterns
5. **Early termination** conditions ekle

Bu ileri algoritmalar, **complex problems'i elegant ÅŸekilde Ã§Ã¶zmenin anahtarÄ±**! Pattern recognition geliÅŸtikÃ§e hangi technique'i ne zaman kullanacaÄŸÄ±nÄ± instinctively anlayacaksÄ±n! ğŸš€ğŸ§ 